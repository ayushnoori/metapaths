---
title: "BioKG Demonstration"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BioKG Demonstration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

# Download BioKG

The following Python script downloads the `ogbl-biokg` (*i.e.*, BioKG) knowledge graph from the [Open Graph Benchmark (OGB)](https://ogb.stanford.edu/docs/linkprop/#ogbl-biokg).

The `ogbl-biokg` dataset is described by OGB as follows:

> "The `ogbl-biokg` dataset is a Knowledge Graph (KG), which we created using data from a large number of biomedical data repositories. It contains 5 types of entities: diseases (10,687 nodes), proteins (17,499), drugs (10,533 nodes), side effects (9,969 nodes), and protein functions (45,085 nodes). There are 51 types of directed relations connecting two types of entities, including 38 kinds of drug-drug interactions, 8 kinds of protein-protein interaction, as well as drug-protein, drug-side effect, function-function relations. All relations are modeled as directed edges, among which the relations connecting the same entity types (e.g., protein-protein, drug-drug, function-function) are always symmetric, i.e., the edges are bi-directional.
>
> This dataset is relevant to both biomedical and fundamental ML research. On the biomedical side, the dataset allows us to get better insights into human biology and generate predictions that can guide downstream biomedical research. On the fundamental ML side, the dataset presents challenges in handling a noisy, incomplete KG with possible contradictory observations. This is because the `ogbl-biokg` dataset involves heterogeneous interactions that span from the molecular scale (e.g., protein-protein interactions within a cell) to whole populations (e.g., reports of unwanted side effects experienced by patients in a particular country). Further, triplets in the KG come from sources with a variety of confidence levels, including experimental readouts, human-curated annotations, and automatically extracted metadata."

```{python download-kg}
import numpy as np
import copy
import json
from ogb.linkproppred import LinkPropPredDataset

dataset = LinkPropPredDataset(name = "ogbl-biokg")

split_edge = dataset.get_edge_split()
train_edge, valid_edge, test_edge = split_edge["train"], split_edge["valid"], split_edge["test"]
graph = dataset[0] # graph: library-agnostic graph object
```

The edge index in the `graph` object is converted into JSON format to be read into R.

```{python edge-types}
print(graph.keys())
edge_index = graph["edge_index_dict"].copy()
```

To make the conversion, the dictionary keys must be renamed (*i.e.*, cannot be tuples).

```{python rename-key}
old_keys = list(edge_index.keys())
for old_name in old_keys:
    new_name = "--".join(old_name)
    edge_index[new_name] = edge_index[old_name]
    del edge_index[old_name]
```

A special numpy encoder is defined, borrowed from [this StackOverflow post](https://stackoverflow.com/questions/57269741/typeerror-object-of-type-ndarray-is-not-json-serializable).

```{python numpy-encoder}
class NumpyEncoder(json.JSONEncoder):
    """ Special json encoder for numpy types """
    def default(self, obj):
        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,
                            np.int16, np.int32, np.int64, np.uint8,
                            np.uint16, np.uint32, np.uint64)):
            return int(obj)
        elif isinstance(obj, (np.float_, np.float16, np.float32,
                              np.float64)):
            return float(obj)
        elif isinstance(obj, (np.ndarray,)):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)
```

Finally, we convert the edge index to JSON and write to a file.

```{python convert-json}
edge_index_json = json.dumps(edge_index, cls = NumpyEncoder)

with open('inst/extdata/edge_index.json', 'a') as f:
    f.write(edge_index_json + '\n')
```

# Parse KG in R

Read the JSON dataset saved previously.

```{r read-kg}
# load libraries
library(data.table)
library(purrr)
library(magrittr)
library(rjson)

# load metapaths library
library(metapaths)

# read data
print(getwd())
biokg = fromJSON(file = "inst/extdata/edge_index.json")
```

Read mappings downloaded from OGB.

```{r read-mappings}
mapping_dir = "inst/extdata/biokg_mappings"

read_mapping = function(mapping_path) {
  mapping = fread(file.path(mapping_dir, mapping_path))
  mapping[, Type := strsplit(mapping_path, "_")[[1]][1]]
  return(mapping)
}

mappings = list.files(mapping_dir) %>%
  .[grepl("entidx2name", .)] %>%
  map_dfr(read_mapping)

mappings = mappings %>% copy() %>%
  setnames(c("ent idx", "ent name"), c("Index", "Name")) %>%
  setcolorder("Type") %>%
  .[, Label := paste(Type, Index, sep = "_")]

```

Create a function to convert the edge list to a `data.table`. Note that the node IDs are specific to each type, so we must add a type-specific prefix.

```{r convert-biokg}
convert_biokg = function(sub_kg, sub_label) {
  
  # split label
  split_label = strsplit(sub_label, "--")[[1]]
  origin_label = paste(split_label[1], sub_kg[[1]], sep = "_")
  destination_label = paste(split_label[3], sub_kg[[2]], sep = "_")
  
  # create data table
  kg_dt = data.table(
    Origin = origin_label,
    Destination = destination_label,
    OriginType = split_label[1],
    DestinationType = split_label[3],
    EdgeType = split_label[2])
  
}
```

Now, map the conversion function over the `biokg` list.

```{r map-convert}
biokg_edge_list = imap_dfr(biokg, convert_biokg)
biokg_node_list = get_node_list(biokg_edge_list)
head(biokg_edge_list)
```

Check that the counts of each node type conform with `graph["num_nodes_dict"]` from the Python script.

| disease | drug  | function | protein | sideeffect |
|:-------:|:-----:|:--------:|:-------:|:----------:|
|  10687  | 10533 |  45085   |  17499  |    9969    |

```{r check-types}
biokg_node_list[, .N, by = NodeType]
```

Add node names from `mappings` table.

```{r add-name}
# add node names
biokg_node_list = merge(biokg_node_list, mappings[, .(Label, Name)], by.x = "Node", by.y = "Label", sort = F) %>%
  setnames("Name", "NodeName")
```

Sample the knowledge graph to generate a small, connected test set.

```{r sample-kg}
# load igraph library
library(igraph)

# generate graph
biokg_graph = igraph::graph.data.frame(biokg_edge_list, vertices = biokg_node_list, directed = T)

# sample random nodes
set.seed(42)
seed_nodes = sample(biokg_node_list$Node, 5000)

# generate induced subgraph
biokg_sample = igraph::induced.subgraph(graph = biokg_graph, vids = seed_nodes)

# get largest connected component
comp = igraph::components(biokg_sample) 
comp_idx = which.max(comp$csize)
lcc = comp$membership %>%
  {names(.)[. == comp_idx]}

# generate connected subgraph
biokg_sub = igraph::induced.subgraph(graph = biokg_graph, vids = lcc)

# generate subsamples node and edge lists
sub_edge_list = biokg_edge_list[Origin %in% lcc & Destination %in% lcc]
sub_node_list = biokg_node_list[Node %in% lcc]

# convenience function
lookup = function(node) {
  # return(sub_node_list[Node == node, NodeName])
  return(biokg_node_list[Node == node, NodeName])
}
```

Save node list and edge list to file.

```{r save-file}
save(sub_edge_list, file = "data/sub_edge_list.rda")
save(sub_node_list, file = "data/sub_node_list.rda")
```

# Test Node Similarity

Check possible edge types.

```{r check-edge}
message("- ", paste(unique(sub_node_list[, NodeType]), collapse = "\n- "))
```

Find hub genes.

```{r find-hubs}
# calculate degree
sub_degrees = degree(biokg_sub)

# find candidate nodes
candidate_nodes = sub_degrees %>%
  .[which(. > 20 & . < 30)] %>% names() %>% .[grepl("protein", .)] %>%
  { sub_node_list[Node %in% ., NodeName] }

cat(paste("HGNC:", candidate_nodes, sep = ""), sep = "\n")

```

Test similarity between an Alzheimer's disease (AD)-related drug (donepezil) and an AD-related pathway ("regulation of amyloid fibril formation").

```{r test-similarity}
total_time = 0
for (i in 1:100) {
  start_time = Sys.time()
  sim_test = get_similarity(
    "drug_762", "function_42893",
    mp = c("drug", "disease", "protein", "function"),
    node_list = biokg_node_list,
    edge_list = biokg_edge_list,
    verbose = F)
  end_time = Sys.time()
  time_required = end_time - start_time
  total_time = total_time + time_required
}
average_time = total_time/100
message("Computed in ", as.character(average_time), " seconds.")

sim_res = sim_test$OriginPaths  %>%
  .[.[["function"]] == "function_36342", ]
```

Visualize identified metapaths in the KG.

```{r visualize-results}
sim_nodes = unique(unlist(sim_res))

# generate connected subgraph
sim_graph = igraph::induced.subgraph(graph = biokg_graph, vids = sim_nodes)

# plot subgraph
plot(sim_graph, vertex.size = 15, edge.arrow.size = 0.25)
```

As a negative control, randomly sample 100 pathways (i.e., nodes of type `"function"` likely not AD-related) and compute the similarity.

```{r test-negative}
set.seed(42)

# sample 100 pathways
random_neg_pathways = biokg_node_list[NodeType == "function", ] %>%
    .[sample(1:nrow(.), 100), ] 
neg_tests = list()
neg_sims = data.table()

# for each pathway, compute similarity
total_time = 0
for (i in 1:100) {
  
  message("Pathway #", i, ": ", random_neg_pathways[i, NodeName])
  
  start_time = Sys.time()
  sim_neg_test = get_similarity(
  "drug_762", random_neg_pathways[i, Node], # "function_29825",
  mp = c("drug", "disease", "protein", "function"),
  metric = c("pc", "npc", "dwpc"),
  node_list = biokg_node_list,
  edge_list = biokg_edge_list,
  verbose = F)
  end_time = Sys.time()
  
  time_required = end_time - start_time
  total_time = total_time + time_required
  
  neg_tests = append(neg_tests, sim_neg_test)
  neg_sims = rbind(neg_sims, sim_neg_test$Similarity[, Pathway := random_neg_pathways[i, NodeName]])
  
}

average_time = total_time/100
message("Computed in ", as.character(average_time), " seconds.")

# calculate statistics (mean, median, SD, etc.)
neg_sims[, sum(Similarity == 0), by = "Metric"]
neg_sims[, mean(Similarity), by = "Metric"]
neg_sims[, median(Similarity), by = "Metric"]
neg_sims[, sd(Similarity), by = "Metric"]

# saveRDS(neg_tests, "<insert file path>.RDS")
# fwrite(neg_sims, "<insert file path>.csv")

```

# Test Set Similarity

Again, test set-to-set similarity by computing similarity scores between three AD-related drugs (i.e., donepezil, memantine, and galantamine) and a set of six AD-related pathways.

```{r test-alzheimer}
# set of three AD drugs
alzheimer_drugs = c("drug_762", "drug_1075", "drug_895")

# set of six AD-related pathways
alzheimer_pathways = c("function_36342", "function_26258", "function_21333", "function_42901", "function_17601", "function_36167")

# compare sets
alzheimer_test = compare_sets(
  alzheimer_drugs,
  alzheimer_pathways,
  mp = c("drug", "disease", "protein", "function"),
  method = c("minimum", "maximum"),
  node_list = biokg_node_list,
  edge_list = biokg_edge_list)
```

As a negative control, test set-to-set similarity by computing similarity scores between the same three AD-related drugs and a set of six randomly subset pathways.

```{r test-random}
set.seed(1234) # selecting different seed

# randomly subset pathways
random_pathways = biokg_node_list[NodeType == "function", ] %>%
  .[sample(1:nrow(.), 6), ]

# compare sets
random_test = compare_sets(
  alzheimer_drugs,
  random_pathways$Node,
  mp = c("drug", "disease", "protein", "function"),
  method = c("minimum", "maximum"),
  node_list = biokg_node_list,
  edge_list = biokg_edge_list)
```

# Package Efficiency

```{r test-efficiency}
set.seed(42)

# get all node types
node_types = unique(biokg_node_list$NodeType)

# list possible edge types from unique(biokg_edge_list$EdgeType)
# excluding "drug-sideeffect" since all sideeffect nodes are terminal
# excluding "protein-function" and "function-function" to prevent uninformative "function" x n metapaths
edge_types = c("disease-protein", "drug-disease", "drug-drug", "drug-protein", "protein-protein")
edge_types = data.table(Origin = map_chr(strsplit(edge_types, "-"), ~.x[1]),
                        Destination = map_chr(strsplit(edge_types, "-"), ~.x[2]))

# list origin types
origin_types = unique(edge_types$Origin)

# list destination types
destination_types = unique(edge_types$Destination)

# define random performance evaluation function
# meta path length must be at least 2
random_test = function(mp_length) {
  
  # sample random origin node
  random_origin = biokg_node_list[NodeType %in% origin_types][Node == sample(Node, 1), ]
  
  # construct random meta path starting at origin
  random_mp = c(random_origin$NodeType)
  for (k in 1:(mp_length - 1)) {
    next_type = edge_types[Origin == tail(random_mp, 1), Destination] %>% sample(1)
    random_mp = append(random_mp, next_type)
  }
  
  # sample random destination node
  random_destination = biokg_node_list %>%
    .[NodeType == tail(random_mp, 1)] %>%
    .[Node == sample(Node, 1), ]
  
  # time similarity search
  start_time = Sys.time()
  sim_result = get_similarity(
    random_origin$Node, random_destination$Node,
    mp = random_mp,
    metric = c("dwpc"),
    node_list = biokg_node_list,
    edge_list = biokg_edge_list,
    verbose = T)
  end_time = Sys.time()
  
  # compute time required
  time_required = end_time - start_time
  
  # construct return object
  out = list(
    Origin = random_origin,
    Destination = random_destination,
    MP = random_mp,
    Time = time_required
  )
  
  return(out)
  
}

# test meta paths with lengths 2-4
length_2 = map(1:50, ~random_test(2))
length_3 = map(1:50, ~random_test(3))
length_4 = map(1:50, ~random_test(4))
all_times = c(length_2, length_3, length_4)

# get times
times_2 =  map_dbl(length_2, ~.x$Time)
times_3 =  map_dbl(length_3, ~.x$Time)
times_4 = map_dbl(length_4, ~.x$Time)

```
